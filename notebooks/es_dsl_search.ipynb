{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Elasticsearch(['http://localhost:9200'])>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import elasticsearch_dsl as dsl\n",
    "import spacy\n",
    "from elasticsearch_dsl import Document, Text, Keyword, Date, Boolean, Float, Nested, DenseVector\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class Article(Document):\n",
    "    title: str = Text()\n",
    "    link: str = Keyword()\n",
    "    published: str = Date()\n",
    "    summary: str = Text()\n",
    "    source: str = Keyword()\n",
    "    embedding: List[float] = DenseVector()\n",
    "    nlp_processed: bool = Boolean()\n",
    "    entities: List[Dict[str, Any]] = Nested()\n",
    "    sentiment: float = Float()\n",
    "\n",
    "    class Index:\n",
    "        name = \"rss_feeds\"\n",
    "\n",
    "    def clean(self):\n",
    "        if not self.embedding:\n",
    "            doc = nlp(self.summary)\n",
    "            self.entities = [{\"text\": ent.text, \"label\": ent.label_} for ent in doc.ents]\n",
    "            self.sentiment = (\n",
    "                doc._.blob.sentiment.polarity\n",
    "            )  # Using spacytextblob for sentiment analysis\n",
    "            self.nlp_processed = True\n",
    "            self.embedding = doc.vector.tolist()\n",
    "\n",
    "dsl.connections.create_connection(hosts=['http://localhost:9200'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3392058203934381 Lauren Lior-Liechtenstein's journey from the arts to medicine\n",
      "0.4280747579199786 MMDC, Concentrix prop up working students\n",
      "-0.01880078985642257 Piolo gagawin ang buhay nina Magalong at Marcos; handang i-give up ang lahat para sa reunion nila ni Juday\n",
      "0.36797330752791274 Spotlight: the UAP's 17th Likha Awardee\n",
      "0.41667625766460326 Leading the way to develop multi-skilled Filipinos\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Specify the sentiment analysis model\n",
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model_name, device=-1)  # device=-1 ensures CPU usage\n",
    "\n",
    "# Load the sentiment analysis and embedding models\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", device=-1)  # device=-1 ensures CPU usage\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')  # Ensure CPU usage\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "input = \"Data careers\"\n",
    "# Use Hugging Face for sentiment analysis\n",
    "sentiment_result = sentiment_pipeline(input[:512])  # Truncate to 512 tokens if necessary\n",
    "sentiment = sentiment_result[0]['score'] if sentiment_result else 0.0\n",
    "\n",
    "# Use SentenceTransformers for embeddings\n",
    "vector = embedding_model.encode(input).tolist()\n",
    "\n",
    "\n",
    "# # Convert the vector to a list and join with commas\n",
    "# vector_list = vector.tolist()\n",
    "# vector_str = ', '.join(map(str, vector_list))\n",
    "# print(f\"Query vector:\\n[{vector_str}]\")\n",
    "\n",
    "s = Article.search(index=\"rss_feeds\")\n",
    "s = s.knn(field=\"embedding\", k=5, num_candidates=10, query_vector=vector)\n",
    "# print(\"Elasticsearch query:\", s.to_dict())\n",
    "\n",
    "response = s.execute()\n",
    "# print(\"Raw response:\", response.to_dict())\n",
    "for hit in response:\n",
    "    # print(hit.summary)\n",
    "#     # print(hit.embedding)\n",
    "    hit_doc = nlp(hit.summary)\n",
    "    query = nlp(input)\n",
    "    similarity = query.similarity(hit_doc)\n",
    "    print(similarity, hit.title)\n",
    "#     print(\"\\n\")\n",
    "print(len(response.hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MORE FOR CALOY\n",
      "\n",
      "\n",
      "‘Laruang de baterya’: Carlos Yulo amuses with ‘Maybe This Time’ dance trend take\n",
      "\n",
      "\n",
      "‘Fake’: Nueva Ecija governor disowns viral congratulatory post for Carlos Yulo\n",
      "\n",
      "\n",
      "Yulo gets house and lot from Century Properties\n",
      "\n",
      "\n",
      "Caloy may payo sa kapatid\n",
      "\n",
      "\n",
      "Castañeda receives recognition in Cebu\n",
      "\n",
      "\n",
      "WATCH: Yulo recalls struggles\n",
      "\n",
      "\n",
      "Carlos Yulo open to join 'Batang Quiapo'\n",
      "\n",
      "\n",
      "Yulo inspirasyon ng mga Kabataan\n",
      "\n",
      "\n",
      "Carlos Yulo ka-look alike Andres Santos meets Olympic champ, GF Chloe San Jose\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Carlos Yulo\"\n",
    "\n",
    "s = Article.search(index=\"rss_feeds\")\n",
    "s = s.query(dsl.query.Match(summary=query))\n",
    "response = s.execute()\n",
    "for hit in response:\n",
    "    print(hit.title)\n",
    "    # print(hit.summary)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
